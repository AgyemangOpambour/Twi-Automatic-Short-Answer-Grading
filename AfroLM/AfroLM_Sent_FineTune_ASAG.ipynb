{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiBDLmCg4tS_",
        "outputId": "c6b197c5-2c50-49c6-b3aa-cbf75a6e2226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pandas sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akSvMm1DHbOs"
      },
      "source": [
        "Fine Tuning AfroLM model to ASAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sxVP-InUSOI",
        "outputId": "3399a080-9540-4ed5-8b10-7c97b4a3972d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at bonadossou/afrolm_active_learning and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Epoch 1 - Training:   2%|▏         | 5/228 [00:02<01:34,  2.36it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  18%|█▊        | 40/228 [00:14<01:06,  2.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  24%|██▍       | 55/228 [00:20<01:01,  2.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  29%|██▉       | 66/228 [00:24<00:55,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  58%|█████▊    | 133/228 [00:47<00:33,  2.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  87%|████████▋ | 199/228 [01:09<00:09,  2.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  91%|█████████ | 208/228 [01:12<00:06,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training:  97%|█████████▋| 222/228 [01:17<00:02,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Training: 100%|██████████| 228/228 [01:19<00:00,  2.87it/s]\n",
            "Epoch 1 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1 - Validation: 100%|██████████| 29/29 [00:02<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "Train Loss: 1.6836\n",
            "Val Loss: 1.3040\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training:  22%|██▏       | 50/228 [00:16<01:00,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  39%|███▊      | 88/228 [00:29<00:47,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  46%|████▌     | 104/228 [00:35<00:42,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  51%|█████▏    | 117/228 [00:39<00:38,  2.85it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  71%|███████   | 161/228 [00:54<00:22,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  72%|███████▏  | 164/228 [00:55<00:21,  2.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  82%|████████▏ | 186/228 [01:03<00:14,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training:  82%|████████▏ | 188/228 [01:03<00:13,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Training: 100%|██████████| 228/228 [01:17<00:00,  2.94it/s]\n",
            "Epoch 2 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.59it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 2 - Validation: 100%|██████████| 29/29 [00:02<00:00, 10.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/6\n",
            "Train Loss: 1.2588\n",
            "Val Loss: 1.1738\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training:  18%|█▊        | 42/228 [00:14<01:03,  2.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  28%|██▊       | 63/228 [00:21<00:55,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  32%|███▏      | 73/228 [00:24<00:53,  2.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  34%|███▍      | 77/228 [00:26<00:51,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  63%|██████▎   | 144/228 [00:48<00:28,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  74%|███████▎  | 168/228 [00:57<00:20,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  86%|████████▌ | 195/228 [01:06<00:11,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training:  90%|████████▉ | 205/228 [01:09<00:07,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Training: 100%|██████████| 228/228 [01:17<00:00,  2.95it/s]\n",
            "Epoch 3 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.65it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 3 - Validation: 100%|██████████| 29/29 [00:02<00:00, 10.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/6\n",
            "Train Loss: 1.1149\n",
            "Val Loss: 1.2359\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training:   2%|▏         | 4/228 [00:01<01:17,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  30%|██▉       | 68/228 [00:23<00:54,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  36%|███▌      | 81/228 [00:27<00:50,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  53%|█████▎    | 121/228 [00:41<00:36,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  69%|██████▉   | 158/228 [00:53<00:23,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  77%|███████▋  | 176/228 [00:59<00:17,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  82%|████████▏ | 187/228 [01:03<00:13,  2.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training:  94%|█████████▍| 215/228 [01:13<00:04,  2.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Training: 100%|██████████| 228/228 [01:17<00:00,  2.95it/s]\n",
            "Epoch 4 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.71it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 4 - Validation: 100%|██████████| 29/29 [00:02<00:00, 10.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/6\n",
            "Train Loss: 0.9720\n",
            "Val Loss: 0.9824\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training:   6%|▌         | 14/228 [00:04<01:13,  2.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  16%|█▌        | 37/228 [00:12<01:04,  2.97it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  22%|██▏       | 50/228 [00:17<01:01,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  22%|██▏       | 51/228 [00:17<01:00,  2.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  56%|█████▌    | 128/228 [00:43<00:34,  2.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  64%|██████▎   | 145/228 [00:49<00:28,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  78%|███████▊  | 177/228 [01:00<00:17,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training:  87%|████████▋ | 199/228 [01:07<00:09,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Training: 100%|██████████| 228/228 [01:17<00:00,  2.95it/s]\n",
            "Epoch 5 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.80it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 5 - Validation: 100%|██████████| 29/29 [00:02<00:00, 10.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/6\n",
            "Train Loss: 0.8858\n",
            "Val Loss: 1.1672\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training:  11%|█         | 24/228 [00:08<01:09,  2.93it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  14%|█▎        | 31/228 [00:10<01:06,  2.94it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  23%|██▎       | 53/228 [00:18<01:00,  2.90it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  58%|█████▊    | 132/228 [00:44<00:32,  2.91it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  69%|██████▉   | 158/228 [00:53<00:23,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  74%|███████▎  | 168/228 [00:57<00:20,  2.95it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  74%|███████▍  | 169/228 [00:57<00:20,  2.92it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training:  84%|████████▍ | 192/228 [01:05<00:12,  2.96it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Training: 100%|██████████| 228/228 [01:17<00:00,  2.94it/s]\n",
            "Epoch 6 - Validation:  48%|████▊     | 14/29 [00:01<00:01, 10.83it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 6 - Validation: 100%|██████████| 29/29 [00:02<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6\n",
            "Train Loss: 0.7509\n",
            "Val Loss: 1.0768\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:  14%|█▍        | 4/29 [00:00<00:02, 11.02it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  62%|██████▏   | 18/29 [00:01<00:01, 10.84it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  83%|████████▎ | 24/29 [00:02<00:00, 10.79it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing: 100%|██████████| 29/29 [00:02<00:00, 11.01it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define dataset class\n",
        "class GradingDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.data = data.reset_index(drop=True)  # Reset index to avoid KeyError\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.data.loc[idx, \"Translated Desired Answer\"]\n",
        "        student_answer = self.data.loc[idx, \"Translated Student Answer\"]\n",
        "        average_score = self.data.loc[idx, \"Average Score\"]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            question,\n",
        "            student_answer,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze()\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"average_score\": average_score\n",
        "        }\n",
        "\n",
        "# Load the dataset\n",
        "data_path = \"/content/translated_data_google_twi.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"bonadossou/afrolm_active_learning\"\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
        "tokenizer.model_max_length = 256\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
        "\n",
        "# Define dataset parameters\n",
        "max_length = 256\n",
        "batch_size = 8\n",
        "num_epochs = 6\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# Create datasets and data loaders\n",
        "train_dataset = GradingDataset(train_df, tokenizer, max_length)\n",
        "val_dataset = GradingDataset(val_df, tokenizer, max_length)\n",
        "test_dataset = GradingDataset(test_df, tokenizer, max_length)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Fine-tuning loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Epoch {} - Training\".format(epoch + 1)):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        average_scores = batch[\"average_score\"].to(device).float()  # Convert to float\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predicted_scores = outputs.logits.squeeze()\n",
        "\n",
        "        loss = loss_fn(predicted_scores, average_scores)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Epoch {} - Validation\".format(epoch + 1)):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            average_scores = batch[\"average_score\"].to(device).float()  # Convert to float\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predicted_scores = outputs.logits.squeeze()\n",
        "\n",
        "            loss = loss_fn(predicted_scores, average_scores)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    # Print training and validation metrics for each epoch\n",
        "    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
        "    print(\"Train Loss: {:.4f}\".format(train_loss))\n",
        "    print(\"Val Loss: {:.4f}\".format(val_loss))\n",
        "    print()\n",
        "\n",
        "# Evaluation on test set\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        average_scores = batch[\"average_score\"].to(device).float()  # Convert to float\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predicted_scores = outputs.logits.squeeze()\n",
        "\n",
        "        loss = loss_fn(predicted_scores, average_scores)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        predictions.extend(predicted_scores.tolist())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "# Convert predictions to binary labels (e.g., pass/fail)\n",
        "binary_predictions = [1 if score >= 0.5 else 0 for score in predictions]\n",
        "binary_labels = [1 if score >= 0.5 else 0 for score in test_df[\"Average Score\"]]\n",
        "\n",
        "# Calculate accuracy and mean absolute error (MAE)\n",
        "accuracy = accuracy_score(binary_labels, binary_predictions)\n",
        "mae = mean_absolute_error(test_df[\"Average Score\"], predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsh2AFYLNrUk",
        "outputId": "b78cac50-4770-430c-bf59-3c21c16246e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Mean Absolute Error (MAE): 0.6328\n",
            "Mean Squared Error (MSE): 0.8459\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "print(\"Mean Absolute Error (MAE): {:.4f}\".format(mae))\n",
        "print(\"Mean Squared Error (MSE): {:.4f}\".format(test_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOMnH0RhOhX0",
        "outputId": "35486ac6-f9c4-46d0-916b-d30e4e7c3b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:  33%|███▎      | 19/57 [00:01<00:04,  9.21it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  39%|███▊      | 22/57 [00:02<00:03,  9.25it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  42%|████▏     | 24/57 [00:02<00:03,  9.70it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  49%|████▉     | 28/57 [00:02<00:02, 10.00it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing:  77%|███████▋  | 44/57 [00:04<00:01,  9.90it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Testing: 100%|██████████| 57/57 [00:05<00:00, 10.19it/s]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "# Load the test dataset\n",
        "test_data_path = \"/content/trans_test_data_google_twi_full.csv\"\n",
        "df_test = pd.read_csv(test_data_path)\n",
        "df_test = df_test.dropna(axis=1, how='all')\n",
        "\n",
        "test_dataset = GradingDataset(df_test, tokenizer, max_length)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predicted_scores = outputs.logits.squeeze()\n",
        "\n",
        "      # Convert predicted_scores to a NumPy array and then round up the scores to two decimal places\n",
        "        rounded_predictions = [min(round(score.item(), 2), 5.0) for score in predicted_scores]\n",
        "\n",
        "\n",
        "        predictions.extend(rounded_predictions)\n",
        "\n",
        "# Round up the predicted scores to two decimal places\n",
        "rounded_predictions = [round(score, 2) for score in predictions]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErsyIRiwdwER",
        "outputId": "00638e7d-6cb5-42f9-8217-a69c1cf31771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.7285274725274725\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_test[\"Predicted Score\"] = rounded_predictions\n",
        "\n",
        "# Calculate the mean absolute error of the test set\n",
        "\n",
        "true_scores = df_test['Average Score'].values\n",
        "predicted_scores = df_test['Predicted Score'].values\n",
        "\n",
        "mae = mean_absolute_error(true_scores, predicted_scores)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "\n",
        "# Drop the \"score_avg\" column\n",
        "df_test.drop('Average Score', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "output_csv_path = \"/content/predicted_test_csv_twi.csv\"\n",
        "df_test.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Convert predictions and labels to numpy arrays\n",
        "predictions = np.array(predicted_scores)\n",
        "\n",
        "# labels = np.array(test_df[\"Average Score\"])\n",
        "labels = np.array(true_scores)\n",
        "\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(labels, predictions, label='Predicted Scores')\n",
        "plt.xlabel(\"True Scores\")\n",
        "plt.ylabel(\"Predicted Scores\")\n",
        "plt.title(\"True Scores vs Predicted Scores\")\n",
        "\n",
        "# Add a line plot for reference\n",
        "plt.plot([min(labels), max(labels)], [min(labels), max(labels)], color='red', linestyle='--', label='Ideal Line')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a PNG file\n",
        "plt.savefig(\"/content/scatter_plot.png\", dpi=300)  # Replace \"scatter_plot.png\" with your desired file name/path\n",
        "plt.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}